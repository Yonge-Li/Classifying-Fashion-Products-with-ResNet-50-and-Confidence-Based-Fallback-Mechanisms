{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7909ef3f-d1a7-408a-b14f-ac9b8957d936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Annie/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\Annie\\miniconda3\\envs\\DL\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Annie\\miniconda3\\envs\\DL\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726268277d9349428b185cb02a74334c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.jpg,.jpeg,.png', description='Upload Image')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ab95ef25e843348cafc59a90252196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365f369bfe924a3987b0a559f8242670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Classify Image', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import io\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'save_path': './balanced_model_with_others.pth',\n",
    "    'subclass_threshold': 0.7,\n",
    "    'mainclass_threshold': 0.7,  \n",
    "    'main_classes': ['Clothing', 'Bags', 'Shoes'],\n",
    "    'subclass_to_idx': {\n",
    "        'Dresses': 0,\n",
    "        'Skirts': 1,\n",
    "        'Outerwear': 2,\n",
    "        'Shoulder Bags': 3,\n",
    "        'Tote Bags': 4,\n",
    "        'Clutches': 5,\n",
    "        'High Heels': 8,\n",
    "        'Boots': 7,\n",
    "        'Flats': 6\n",
    "    },\n",
    "    'subclass_to_main': [\n",
    "        0,  # Dresses → Clothing\n",
    "        0,  # Skirts → Clothing\n",
    "        0,  # Outerwear → Clothing\n",
    "        1,  # Shoulder Bags → Bags\n",
    "        1,  # Tote Bags → Bags\n",
    "        1,  # Clutches → Bags\n",
    "        2,  # High Heels → Shoes\n",
    "        2,  # Boots → Shoes\n",
    "        2   # Flats → Shoes\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda image: image.convert(\"RGB\")),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load model\n",
    "class HierarchicalResNet(torch.nn.Module):\n",
    "    def __init__(self, num_main_classes, num_sub_classes):\n",
    "        super().__init__()\n",
    "        self.base = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "        num_ftrs = self.base.fc.in_features\n",
    "        self.base.fc = torch.nn.Identity()\n",
    "        self.main_classifier = torch.nn.Linear(num_ftrs, num_main_classes)\n",
    "        self.sub_classifier = torch.nn.Linear(num_ftrs, num_sub_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.base(x)\n",
    "        main_output = self.main_classifier(features)\n",
    "        sub_output = self.sub_classifier(features)\n",
    "        return main_output, sub_output\n",
    "\n",
    "# Initialize model\n",
    "num_main_classes = len(config['main_classes'])\n",
    "num_sub_classes = len(config['subclass_to_idx'])\n",
    "model = HierarchicalResNet(num_main_classes, num_sub_classes).to(config['device'])\n",
    "model.load_state_dict(torch.load(config['save_path'], map_location=config['device']))\n",
    "model.eval()\n",
    "\n",
    "# Mapping for display\n",
    "idx_to_subclass = {v: k for k, v in config['subclass_to_idx'].items()}\n",
    "\n",
    "# Upload widget\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='.jpg,.jpeg,.png',\n",
    "    multiple=False,\n",
    "    description='Upload Image'\n",
    ")\n",
    "\n",
    "# Output display\n",
    "out = widgets.Output()\n",
    "display(uploader, out)\n",
    "\n",
    "# Classification button callback\n",
    "def on_classify_click(b):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        if not uploader.value:\n",
    "            print(\"Please upload an image first.\")\n",
    "            return\n",
    "            \n",
    "        # Get uploaded file content\n",
    "        file_info = uploader.value[0]\n",
    "        content = file_info['content']\n",
    "        image = Image.open(io.BytesIO(content))\n",
    "\n",
    "        try:\n",
    "            # Display image\n",
    "            image = Image.open(io.BytesIO(content))\n",
    "            display(image.resize((224, 224)))\n",
    "            \n",
    "            # Preprocess and classify\n",
    "            image_tensor = transform(image).unsqueeze(0).to(config['device'])\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                main_out, sub_out = model(image_tensor)\n",
    "                main_probs = torch.softmax(main_out, dim=1)[0]\n",
    "                sub_probs = torch.softmax(sub_out, dim=1)[0]\n",
    "                \n",
    "            main_conf, main_pred = torch.max(main_probs, 0)\n",
    "            sub_conf, sub_pred = torch.max(sub_probs, 0)\n",
    "\n",
    "            # Check if main class is too uncertain\n",
    "            if main_conf.item() < config['mainclass_threshold']:\n",
    "                print(\"\\n=== Prediction Results ===\")\n",
    "                print(f\"Main class confidence {main_conf.item():.4f} is lower than threshold {config['mainclass_threshold']}\")\n",
    "                print(\"Final classification: Unknown / Others\")\n",
    "                print(\"\\nMain class probabilities:\")\n",
    "                for i, prob in enumerate(main_probs):\n",
    "                    print(f\"{config['main_classes'][i]}: {prob.item():.4f}\")\n",
    "                print(\"\\nTop 3 subclass probabilities:\")\n",
    "                topk_values, topk_indices = torch.topk(sub_probs, 3)\n",
    "                for val, idx in zip(topk_values, topk_indices):\n",
    "                    sub_name = idx_to_subclass.get(idx.item(), f\"Subclass_{idx.item()}\")\n",
    "                    print(f\"{sub_name}: {val.item():.4f}\")\n",
    "                return\n",
    "\n",
    "            # Continue with normal prediction logic\n",
    "            sub_name = idx_to_subclass.get(sub_pred.item(), f\"Unknown Subclass\")\n",
    "            belongs_to_main = config['subclass_to_main'][sub_pred.item()] == main_pred.item()\n",
    "            meets_threshold = sub_conf.item() >= config['subclass_threshold']\n",
    "            \n",
    "            print(\"\\n=== Prediction Results ===\")\n",
    "            print(f\"Main class: {config['main_classes'][main_pred.item()]} (Confidence: {main_conf.item():.4f})\")\n",
    "            print(f\"Subclass: {sub_name} (Confidence: {sub_conf.item():.4f})\")\n",
    "            \n",
    "            if belongs_to_main and meets_threshold:\n",
    "                print(\"\\nDecision: Use subclass prediction\")\n",
    "                print(f\"Final classification: {config['main_classes'][main_pred.item()]} -> {sub_name}\")\n",
    "            else:\n",
    "                print(\"\\nDecision: Fall back to main class prediction\")\n",
    "                reasons = []\n",
    "                if not belongs_to_main:\n",
    "                    reasons.append(\"Subclass does not belong to predicted main class\")\n",
    "                if not meets_threshold:\n",
    "                    reasons.append(f\"Subclass confidence {sub_conf.item():.4f} < threshold {config['subclass_threshold']}\")\n",
    "                print(f\"Reason: {', '.join(reasons)}\")\n",
    "                print(f\"Final classification: {config['main_classes'][main_pred.item()]}\")\n",
    "            \n",
    "            print(\"\\nMain class probabilities:\")\n",
    "            for i, prob in enumerate(main_probs):\n",
    "                print(f\"{config['main_classes'][i]}: {prob.item():.4f}\")\n",
    "            \n",
    "            print(\"\\nTop 3 subclass probabilities:\")\n",
    "            topk_values, topk_indices = torch.topk(sub_probs, 3)\n",
    "            for val, idx in zip(topk_values, topk_indices):\n",
    "                sub_name = idx_to_subclass.get(idx.item(), f\"Subclass_{idx.item()}\")\n",
    "                print(f\"{sub_name}: {val.item():.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {str(e)}\")\n",
    "\n",
    "# Classification button\n",
    "classify_btn = widgets.Button(description=\"Classify Image\")\n",
    "classify_btn.on_click(on_classify_click)\n",
    "display(classify_btn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d7ed6-c6c9-4ac6-9743-b601cc4b7de8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL)",
   "language": "python",
   "name": "python3-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
